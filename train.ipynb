{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-30T12:54:05.523400Z",
     "start_time": "2025-07-30T12:54:00.902876Z"
    }
   },
   "source": [
    "from model import build_gpt_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from dataset import GPTChatDataset\n",
    "from tokenizer_utils import SubwordTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T12:54:05.530602Z",
     "start_time": "2025-07-30T12:54:05.527858Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "SEQ_LEN = 128"
   ],
   "id": "e5fcfed8cb10b63a",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T12:54:06.526616Z",
     "start_time": "2025-07-30T12:54:05.759570Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "from convert import load\n",
    "lines = load()\n"
   ],
   "id": "7cc3c00dd49d83c5",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T12:54:06.542844Z",
     "start_time": "2025-07-30T12:54:06.532472Z"
    }
   },
   "cell_type": "code",
   "source": "print(len(lines))",
   "id": "42a786b81cde10d3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72603\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T12:54:06.577477Z",
     "start_time": "2025-07-30T12:54:06.554492Z"
    }
   },
   "cell_type": "code",
   "source": "train_lines, test_lines = train_test_split(lines, test_size=0.2, random_state = 42)\n",
   "id": "2405521965bd7dad",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T12:54:06.589213Z",
     "start_time": "2025-07-30T12:54:06.583633Z"
    }
   },
   "cell_type": "code",
   "source": "print(len(train_lines))",
   "id": "d4efa6ff13d839b9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58082\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T12:54:06.635846Z",
     "start_time": "2025-07-30T12:54:06.607124Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = SubwordTokenizer(\"saved/vi_bpe.model\")\n",
    "\n",
    "pad_id = tokenizer.word2idx[\"<pad>\"]\n",
    "\n",
    "train_dataset = GPTChatDataset(train_lines, tokenizer, seq_len= SEQ_LEN )\n",
    "test_dataset = GPTChatDataset(test_lines, tokenizer, seq_len= SEQ_LEN)\n",
    "\n"
   ],
   "id": "fb85893e192fdd64",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T12:54:06.648007Z",
     "start_time": "2025-07-30T12:54:06.643775Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from statistics import mean\n",
    "# \n",
    "# lengths = [len(tokenizer.tokenize(line)) for line in lines]\n",
    "# print(\"Trung b√¨nh:\", mean(lengths), \"| Max:\", max(lengths), \"| Min:\", min(lengths))"
   ],
   "id": "a78e7693d5ba0f47",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T12:54:06.661066Z",
     "start_time": "2025-07-30T12:54:06.654046Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def collate_fn(batch):\n",
    "    decoder_input = torch.stack([item[\"decoder_input\"] for item in batch])\n",
    "    decoder_mask = torch.stack([item[\"decoder_mask\"] for item in batch])\n",
    "    label = torch.stack([item[\"label\"] for item in batch])\n",
    "\n",
    "    return {\n",
    "        \"decoder_input\": decoder_input,      # (batch_size, seq_len)\n",
    "        \"decoder_mask\": decoder_mask,        # (batch_size, 1, seq_len, seq_len)\n",
    "        \"label\": label                       # (batch_size, seq_len)\n",
    "    }\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)"
   ],
   "id": "cbe9ad58ad4a400e",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T12:54:06.673007Z",
     "start_time": "2025-07-30T12:54:06.668969Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# for word in tokenizer.word2idx:\n",
    "#     print(word)"
   ],
   "id": "b7a3d504ca079f36",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T12:54:09.242537Z",
     "start_time": "2025-07-30T12:54:06.679467Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = build_gpt_model(len(tokenizer.word2idx), seq_len= SEQ_LEN).to(device)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ],
   "id": "687cf8df0c44f9df",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-07-30T12:54:09.251205Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n_epochs = 3\n",
    "best_val_loss = float(\"inf\")\n",
    "save_path     = \"saved/best_model.pth\"\n",
    "os.makedirs(\"saved\", exist_ok=True)\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "\n",
    "    for batch in tqdm(train_loader, desc=f\"[Epoch {epoch}] Validating\"):\n",
    "        decoder_input = batch[\"decoder_input\"].to(device)\n",
    "        decoder_mask = batch[\"decoder_mask\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "\n",
    "        # Forward\n",
    "        output = model(decoder_input, decoder_mask)  \n",
    "\n",
    "        # Loss\n",
    "        output = output.view(-1, output.shape[-1])\n",
    "        labels = labels.view(-1)\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        # Backprop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    \n",
    "    \n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            decoder_input = batch[\"decoder_input\"].to(device)\n",
    "            decoder_mask = batch[\"decoder_mask\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "\n",
    "            output = model(decoder_input, decoder_mask)  \n",
    "\n",
    "            output = output.view(-1, output.shape[-1])\n",
    "            labels = labels.view(-1)\n",
    "            loss = criterion(output, labels)\n",
    "\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(test_loader)\n",
    "    \n",
    "    print(f\"[Epoch {epoch+1}] Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    \n",
    "    # Save model if best\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        print(\"Saved best model.\")\n"
   ],
   "id": "eeab1592260173ba",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 0] Validating:   0%|          | 3/1816 [00:03<35:11,  1.16s/it]"
     ]
    }
   ],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
